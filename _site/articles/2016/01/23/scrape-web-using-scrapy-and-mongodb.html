<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>scrape web using scrapy and mongodb</title>
    <meta name="description" content="prepare">

    <link rel="stylesheet" href=" /css/customer/syntax.css ">
    <link rel="stylesheet" href=" /css/customer/customer.css ">
    <!-- bootstrap3 -->
    <link rel="stylesheet" href=" /css/bootstrap3/css/bootstrap.min.css ">
    <link rel="canonical" href="http://smileboywtu.github.io/articles/2016/01/23/scrape-web-using-scrapy-and-mongodb.html">

    <script data-isso="//121.42.178.129" data-isso-lang="en" data-isso-css="true" src="//121.42.178.129/js/embed.min.js"></script>
    <!-- bootstrap 3 -->
    <script src=" /css/bootstrap3/js/jquery-1.12.0.min.js "></script>
    <script src=" /css/bootstrap3/js/bootstrap.min.js "></script>

    
    <script>
        $(document).ready(function() {
            $("#id-page-scrape web using scrapy and mongodb-title").addClass("active");
        });
    </script>
    

</head>


<body>
    <div>
        <header>

    <nav class="navbar navbar-default">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="/">Coder Life</a>
            </div>

            <div class="collapse navbar-collapse">
                <ul class="nav navbar-nav">
                    <li id="id-page-Projects-title">
                        <a href=" /Projects/ ">Projects</a>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Explore <span class="caret"></span></a>
                        <ul class="dropdown-menu">
                            <li id="id-page-About-title"><a href=" /About/ ">About</a></li>
                            <li role="separator" class="divider"></li>
                            <li><a href="https://github.com/smileboywtu">GitHub</a></li>
                        </ul>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

</header>


        <div class="container-fluid">
            <div class="row default">
                <div class="col-lg-6">
                    <div class="post" itemscope itemtype="http://schema.org/BlogPosting">

    <h2 class="post-title">scrape web using scrapy and mongodb</h2>

    <p class="post-meta">
        <small>
            <time datetime="2016-01-23T14:19:20+08:00" itemprop="datePublished">
                Jan 23, 2016
            </time>
        </small>
    <p>

    <div class="post-content">
        <h1 id="prepare">prepare</h1>

<p>you’d better do this in a virtual env.</p>

<ul>
  <li>install mongodb</li>
</ul>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">pip</span> <span class="n">install</span> <span class="n">pymongo</span></code></pre></div>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># because the mongodb is cs mode database</span>
<span class="c"># you need to install the server</span>
<span class="c"># on ubuntu just use apt command install mongodb</span>
<span class="c"># follow the link: https://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/</span>
sudo apt-get install -y mongodb-org</code></pre></div>

<ul>
  <li>install scrapy</li>
</ul>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">pip</span> <span class="n">install</span> <span class="n">scrapy</span></code></pre></div>

<h1 id="description">description</h1>

<p>use scrapy to scrapy some new questions from stackoverflow and save the data into the mongodb.</p>

<h1 id="details">details</h1>

<p>if you use the virutal env, make sure you are inside the environment.</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">scrapy startproject stackoverflow
    <span class="nb">cd </span>stackoverflow
    tree .
    ├── scrapy.cfg
    └── stackoverflow
        ├── __init__.py
        ├── items.py
        ├── pipelines.py
        ├── settings.py
        └── spiders
            └── __init__.py</code></pre></div>

<p><strong>1.</strong> edit the items</p>

<p><em>here we just record the title and url field.</em></p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># items.py</span>
<span class="k">class</span> <span class="nc">StackoverflowItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span></code></pre></div>

<p><strong>2.</strong> create the spiders</p>

<p><em>before we create the spiders, we need to find out what path
we will use to scrapy the data, if you are not familiar with
the xpath, you can find more detail in the xpath documents.
xpath like a file path in the file system, use xpath the
scrapy can find out the data we need.</em></p>

<p><em>you can use the web browser to help you find out the xpath.</em></p>

<ol>
  <li>use firefox or chrome open the web you want to scrapy.</li>
  <li>select the item you are interested in.</li>
  <li>right mouse key and select inspect elements.</li>
  <li>after you get the html tag, just right mouse key get the xpath.</li>
</ol>

<p><img class="img-responsive" src="/downloads/posts/scrape_stackoverflow/scrapy_item.png" alt="scrapy image" /></p>

<p><em>if you select this article title, and follow the step, you will find
the xpath of this site is: “/html/body/div/div/article/header/h1”</em></p>

<p><em>if you want to test if you get the correct xpath, you can use the browser
js console to test:</em></p>

<p><img class="img-responsive" src="/downloads/posts/scrape_stackoverflow/js_test_xpath.png" alt="js text" /></p>

<p><strong>3.</strong> ready to create the spiders</p>

<ul>
  <li>here we just want to scrape the website:<br />
“http://stackoverflow.com/questions”</li>
  <li>
    <p>we just want to get title and url item as definition in items.py.</p>
  </li>
  <li>get the xpath of title:
“//*[@id=’question-summary-34959124’]/div[2]/h3/a/text()”</li>
</ul>

<blockquote>
  <p>notice that: if you want to extract the title text out you need to append
text() function. please use the single quote inside the double quote.</p>
</blockquote>

<ul>
  <li>get the xpath of url:
“//*[@id=’question-summary-34959124’]/div[2]/h3/a/@href”</li>
</ul>

<blockquote>
  <p>notice that: if you want to get the attribute out you need to use operator
@ before the attribute of html. please use the single quote inside
the double quote.</p>
</blockquote>

<ul>
  <li>inspect the source html structure
you may test successfully under the js console inside the browser, but you’ll
get error when use the scrapy to scrapy the test out.</li>
</ul>

<p>what you really want to do is to scrapy the whole list of the question, but now
you just scrapy only a specific one.</p>

<div class="highlight"><pre><code class="language-html" data-lang="html"><span class="c">&lt;!-- question list --&gt;</span>
<span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">&quot;questions&quot;</span><span class="nt">&gt;</span>
    <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;question-summary&quot;</span><span class="nt">&gt;</span> ... <span class="nt">&lt;/div&gt;</span>
    .
    .
    .
<span class="nt">&lt;/div&gt;</span>

<span class="c">&lt;!-- div for each question --&gt;</span>
<span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;summary&quot;</span><span class="nt">&gt;</span>
    <span class="nt">&lt;h3&gt;</span>
        <span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">&quot;example.com&quot;</span><span class="nt">&gt;</span>title<span class="nt">&lt;/a&gt;</span>
    <span class="nt">&lt;/h3&gt;</span>
<span class="nt">&lt;/div&gt;</span></code></pre></div>

<p><strong>4.</strong> write the spiders</p>

<p>here comes the source code, do more test in scrapy bash.</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="lineno"> 1</span> <span class="c"># create spider.py inside the spiders/question_newest.py</span>
<span class="lineno"> 2</span> <span class="c"># or you can use the scrapy to create the spider for you:</span>
<span class="lineno"> 3</span> <span class="c"># scrapy genspider -t basic question_newest http://stackoverflow.com/questions</span>
<span class="lineno"> 4</span> <span class="sd">&quot;&quot;&quot;</span>
<span class="lineno"> 5</span> <span class="sd">    this spider crawl the title and url from the</span>
<span class="lineno"> 6</span> <span class="sd">    stackoverflow newest questions list.</span>
<span class="lineno"> 7</span> <span class="sd">&quot;&quot;&quot;</span>
<span class="lineno"> 8</span> 
<span class="lineno"> 9</span> <span class="kn">import</span> <span class="nn">scrapy</span>
<span class="lineno">10</span> <span class="kn">from</span> <span class="nn">stackoverflow.items</span> <span class="kn">import</span> <span class="n">StackoverflowItem</span>
<span class="lineno">11</span> 
<span class="lineno">12</span> <span class="n">stackoverflow_url</span> <span class="o">=</span> <span class="s">u&quot;http://stackoverflow.com&quot;</span>
<span class="lineno">13</span> <span class="n">questions_xpath</span> <span class="o">=</span> <span class="s">&quot;//div[@class=&#39;summary&#39;]/h3&quot;</span>
<span class="lineno">14</span> 
<span class="lineno">15</span> 
<span class="lineno">16</span> <span class="k">class</span> <span class="nc">NewestQuestionSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
<span class="lineno">17</span>     <span class="n">name</span> <span class="o">=</span> <span class="s">&quot;newest_question&quot;</span>
<span class="lineno">18</span>     <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;http://stackoverflow.com/questions&quot;</span><span class="p">]</span>
<span class="lineno">19</span>     <span class="n">start_urls</span> <span class="o">=</span> <span class="p">(</span>
<span class="lineno">20</span>         <span class="s">&#39;http://stackoverflow.com/questions&#39;</span><span class="p">,</span>
<span class="lineno">21</span>     <span class="p">)</span>
<span class="lineno">22</span> 
<span class="lineno">23</span>     <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
<span class="lineno">24</span>         <span class="n">questions</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="n">questions_xpath</span><span class="p">)</span>
<span class="lineno">25</span>         <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">questions</span><span class="p">:</span>
<span class="lineno">26</span>             <span class="n">item</span> <span class="o">=</span> <span class="n">StackoverflowItem</span><span class="p">()</span>
<span class="lineno">27</span>             <span class="n">item</span><span class="p">[</span><span class="s">&#39;title&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">question</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&quot;a/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="lineno">28</span>             <span class="n">item</span><span class="p">[</span><span class="s">&#39;url&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">stackoverflow_url</span> <span class="o">+</span> \
<span class="lineno">29</span>                 <span class="n">question</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&quot;a/@href&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="lineno">30</span>             <span class="k">yield</span> <span class="n">item</span></code></pre></div>

<h1 id="test-scrapy">test scrapy</h1>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># scrape the stackoverflow newest quesion and save it into the json file.</span>
<span class="c"># if you do not use -o result.json. you won&#39;t get any output except log.</span>
scrapy crawl question_newest -o result.json</code></pre></div>

<p><img class="img-responsive" src="/downloads/posts/scrape_stackoverflow/result.png" alt="result json" /></p>

<h1 id="use-the-mongodb-save-the-result">use the mongodb save the result</h1>

<p>in scrapy if you want to use the mongodb or other database to save the
result( the item return ) to database, you can use the pipeline interface
to deal with the item.</p>

<p>you can find settings.py and pipelines.py inside your scrapy directory.
just enable the pipeline setting inside the settings.py</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># set up the mongodb</span>
<span class="n">MONGODB_URL</span> <span class="o">=</span> <span class="s">&quot;localhost:27017&quot;</span>
<span class="n">MONGODB_DB</span> <span class="o">=</span> <span class="s">&quot;stackoverflow&quot;</span>

<span class="c"># Configure item pipelines</span>
<span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">&#39;stackoverflow.pipelines.MongodbPipeline&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
<span class="p">}</span></code></pre></div>

<p>customer the pipeline class inside the pipelines.py file:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="lineno"> 1</span> <span class="sd">&quot;&quot;&quot;</span>
<span class="lineno"> 2</span> 
<span class="lineno"> 3</span> <span class="sd">pipeline to save the question inside the mongodb server.</span>
<span class="lineno"> 4</span> 
<span class="lineno"> 5</span> <span class="sd">&quot;&quot;&quot;</span>
<span class="lineno"> 6</span> 
<span class="lineno"> 7</span> <span class="kn">import</span> <span class="nn">pymongo</span>
<span class="lineno"> 8</span> 
<span class="lineno"> 9</span> 
<span class="lineno">10</span> <span class="k">class</span> <span class="nc">MongodbPipeline</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="lineno">11</span> 
<span class="lineno">12</span>     <span class="n">collection_name</span> <span class="o">=</span> <span class="s">&#39;newest_question&#39;</span>
<span class="lineno">13</span> 
<span class="lineno">14</span>     <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mongo_uri</span><span class="p">,</span> <span class="n">mongo_db</span><span class="p">):</span>
<span class="lineno">15</span>         <span class="bp">self</span><span class="o">.</span><span class="n">mongo_uri</span> <span class="o">=</span> <span class="n">mongo_uri</span>
<span class="lineno">16</span>         <span class="bp">self</span><span class="o">.</span><span class="n">mongo_db</span> <span class="o">=</span> <span class="n">mongo_db</span>
<span class="lineno">17</span> 
<span class="lineno">18</span>     <span class="nd">@classmethod</span>
<span class="lineno">19</span>     <span class="k">def</span> <span class="nf">from_crawler</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">crawler</span><span class="p">):</span>
<span class="lineno">20</span>         <span class="k">return</span> <span class="n">cls</span><span class="p">(</span>
<span class="lineno">21</span>             <span class="n">mongo_uri</span><span class="o">=</span><span class="n">crawler</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&#39;MONGODB_URL&#39;</span><span class="p">),</span>
<span class="lineno">22</span>             <span class="n">mongo_db</span><span class="o">=</span><span class="n">crawler</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&#39;MONGODB_DB&#39;</span><span class="p">,</span> <span class="s">&#39;defautlt-test&#39;</span><span class="p">)</span>
<span class="lineno">23</span>         <span class="p">)</span>
<span class="lineno">24</span> 
<span class="lineno">25</span>     <span class="k">def</span> <span class="nf">open_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
<span class="lineno">26</span>         <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">pymongo</span><span class="o">.</span><span class="n">MongoClient</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mongo_uri</span><span class="p">)</span>
<span class="lineno">27</span>         <span class="bp">self</span><span class="o">.</span><span class="n">db</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">mongo_db</span><span class="p">]</span>
<span class="lineno">28</span> 
<span class="lineno">29</span>     <span class="k">def</span> <span class="nf">close_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
<span class="lineno">30</span>         <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="lineno">31</span> 
<span class="lineno">32</span>     <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
<span class="lineno">33</span>         <span class="bp">self</span><span class="o">.</span><span class="n">db</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">collection_name</span><span class="p">]</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">item</span><span class="p">))</span>
<span class="lineno">34</span>         <span class="k">return</span> <span class="n">item</span></code></pre></div>

<h1 id="test-the-mongodb">test the mongodb</h1>

<p>before you run the spider, you need to start the mongod service.</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># ubuntu 14.04</span>
sudo service mongod start

<span class="c"># run spider</span>
scrapy crawl newest_question

<span class="c"># after done, check your mongodb</span>
mongo shell

<span class="c"># show database</span>
show db

<span class="c"># switch to stackoverflow</span>
use stackoverflow

<span class="c"># find out data</span>
db.newest_question.find<span class="o">()</span></code></pre></div>

<p>all done here, hope you’ll enjoy with it.</p>

    </div>

    
    <hr>
    <div class="post-comments">
        <section id="isso-thread"></section>
    </div>

    

</div>

                </div>
            </div>
        </div>

        <footer class="footer">
    <div class="container-fluid">
        <div class="container row">
            <div class="col-lg-3">
                <p class="text-muted text-left text-primary">
                    <small>Designed By Smile Boy.</small>
                </p>
            </div>
            <div class="col-lg-3">
                <a href="https://github.com/smileboywtu">
                    <span class="icon"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span>
                </a>
            </div>
        </div>
    </div>
</footer>

    </div>
</body>


</html>
